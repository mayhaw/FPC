library(rgl)
library(leaps)
library(plotly)
library(rsm)
library(tidyr)
library(lubridate)
library(robfilter)
library(XLConnect)
library(EMSaov)
library(car)
library(boot)
library(ggsignif)
library(lsmeans)
library(multcompView)
library(tibble)
library(purrr)
library(car)
library(proto)
library(gridGraphics)
library(phia)
library(ggstance)
library(lmerTest)
library(multcomp)
library(egg)
library(pracma)
library(plyr);library(dplyr) #YOULL NEED THIS FOR JOIN
library(Hmisc)
library(datapasta)
library(agricolaeplotr)
library(stringr)
library(RODBC) #access database thing
library(Rcrawler)# web scraper
library(rvest) #web scraper
library(xml2)# needed for rvest functions
library(devtools) #needed for TreeLS Github version of package
library(lidR) #for als and tls tree coords etc
library(sf)#Simple features for R
library(raster)
library(rgeos)
# library(arcgisbinding) #for chm stuff from ivan 6/2023; doesnt work b/c "package ‘arcgisbinding’ is not available for this version of R" but would be useuful to define parts of a las using a shp eventually. it's something esri talks about on its website esri.com somewhere as of 6/2023
library(ggpubr) #for chm stuff from ivan 6/2023
library(whitebox) #for chm stuff from ivan 6/2023
library(future) #for chm stuff from ivan 6/2023
library(writexl) #for chm stuff from ivan 6/2023
library(terra) #for chm stuff from ivan 6/2023
library(stars) #for chm stuff from ivan 6/2023
library(spatialEco) #for chm stuff from ivan 6/2023
library(exactextractr) #for chm stuff from ivan 6/2023
library(googledrive)
library(googleVis)
select <- dplyr::select #otherwise it calls MASS's select by default
rename <- dplyr::rename #otherwise it calls plyr's rename by default and it doesn't have the same syntax
wex<- function(x,row.names=FALSE,col.names=TRUE,...) {
write.table(x,file="clipboard-32768",sep="\t",row.names=row.names,col.names=col.names,...)  }
source2 <- function(file, start, end, ...) {
file.lines <- scan(file, what=character(), skip=start-1, nlines=end-start+1, sep='\n')
file.lines.collapsed <- paste(file.lines, collapse='\n')
source(textConnection(file.lines.collapsed), ...)
}
src<-function(fileend){
source(paste0(getwd(),fileend))
}
if("you wnat to do flashcards"==T){
ANSWER<-"yes"
#loops thru and gives one column and the same row next too it one by one
fun <- function(dataf) {
ANSWER <- readline(cat("Are you a satisfied R user?\n\n\n "))
if (substr(ANSWER, 1, 1) == "n")
as.character(print((dataf[i-1,"cyl"])))
else
as.character(print((dataf[i,1])))
as.character(print(rownames(dataf[i,])))
}
#works dont fuck
for(i in c(1:4)){
fun(dataf = mtcars)
}
}
#just merge the main table with year by year===-----
massive<-  "Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-yearbyear-pres.csv"%>%
read.csv(header = T)%>%
merge(.,read.csv("Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-maintable.csv",header = T),by="linkparent",all=T)
wex(massive)
#usually need to login in fresh r-: (also usually need to check the boxt that says allow tidyverse api to see files in drive):
#PICK SEND TO BROWSER
drive_auth(
email = gargle::gargle_oauth_email(),
#path = NULL, shouldn't need this unless it stops remembering sabloszi, in which case Idk what to write here instead of NULL
scopes = "https://www.googleapis.com/auth/drive",
cache = gargle::gargle_oauth_cache(),
use_oob = gargle::gargle_oob_default(),
token = NULL
)
#i used this to get the file list in a google file folder INCLUDING the links etc
#https://drive.google.com/drive/u/0/folders/...[your id here]
#xme <- drive_get(id="1YQacwq8m4320xQgfJ1RNgmZMYFXmKtRI")
#xme <- drive_ls(as_id="1FpjYxZkAfqKEs0jB-oybreMETapXjuuW")
#xme <- drive_ls(drive_get(id="1YQacwq8m4320xQgfJ1RNgmZMYFXmKtRI"))
xme <- drive_ls(drive_get(id="1FpjYxZkAfqKEs0jB-oybreMETapXjuuW"))#usually you want this one which is "Q:\Shared drives\FER - FPC Team\Website\Htmltables\wordpressdownloads\mlfd-forestproductivitycoop"
#see names of the google tibble dribble thing
#xme%>%names()
googledmerge<-xme%>%dplyr::select(c(id,name))
merge(massive,googledmerge,by.x="linkbase.x",by.y="name",all.x=T,all.y=T,sort=T)%>%
head()
merge(massive,googledmerge,by.x="linkbase.x",by.y="name",all.x=T,all.y=T,sort=T)%>%
wex()
merge(massive,googledmerge,by.x="linkbase.x",by.y="name",all.x=T,all.y=T,sort=T)%>%
pull(id)
merge(massive,googledmerge,by.x="linkbase.x",by.y="name",all.x=T,all.y=T,sort=T)%>%
mutate(., glink=ifelse(is.na(id),NA,
paste0("https://drive.google.com/open?id=",id)
)
)%>%
wex()
#just merge the main table with year by year===-----
massive<-     "Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-maintable.csv" %>%
read.csv(header = T)%>%
merge(.,read.csv("Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-yearbyear-pres.csv",header = T),by="linkparent",all=T,
suffixes=c("main","yby"))
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T,sort=T)%>%
mutate(., glink=ifelse(is.na(id),NA,
paste0("https://drive.google.com/open?id=",id)
)
)%>%
wex()
names(massive)
#just merge the main table with year by year===-----
massive<-     "Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-maintable.csv" %>%
read.csv(header = T)%>%
merge(.,read.csv("Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-yearbyear-pres.csv",header = T),by="linkparent",all=T,
suffixes=c(".main",".yby"))
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T,sort=T)%>%
mutate(., glink=ifelse(is.na(id),NA,
paste0("https://drive.google.com/open?id=",id)
)
)%>%
wex()
names(massive)
#just merge the main table with year by year===-----
#massive<-
"Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-maintable.csv" %>%
read.csv(header = T)%>%
merge(.,read.csv("Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-yearbyear-pres.csv",header = T),by="linkparent",all=T,
suffixes=c(".main",".yby"))%>%
names()
#just merge the main table with year by year===-----
#massive<-
"Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-maintable.csv" %>%
read.csv(header = T)%>%
merge(.,read.csv("Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-yearbyear-pres.csv",header = T),by="linkparent",all=T,
suffixes=c(".main",".yby"))%>%
names()
#just merge the main table with year by year===-----
massive<-
"Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-maintable.csv" %>%
read.csv(header = T)%>%
merge(.,read.csv("Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-yearbyear-pres.csv",header = T),by="linkparent",all=T,
suffixes=c(".main",".yby"))
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T)%>%
mutate(., glink=ifelse(is.na(id),NA,
paste0("https://drive.google.com/open?id=",id)
)
)%>%
wex()
head(googledmerge)
wex(massive)
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T)%>%
wex()
massive$linkbase.yby
massive$linkbase.yby%>%wex()
#just merge the main table with year by year===-----
massive<-
"Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-maintable.csv" %>%
read.csv(header = T,encoding="UTF-8")%>%
merge(.,read.csv("Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-yearbyear-pres.csv",header = T,encoding="UTF-8"),
by="linkparent",all=T,
suffixes=c(".main",".yby"))
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T)%>%
wex()
warnings()
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T)%>%
write.csv(.,file="Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-bigcombo.csv",fileEncoding = "UTF-8")
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T)%>%
view()
#just merge the main table with year by year===-----
massive<-
"Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-maintable.csv" %>%
read.csv(header = T,encoding="Latin-1")%>%
merge(.,read.csv("Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-yearbyear-pres.csv",header = T,encoding="Latin-1"),
by="linkparent",all=T,
suffixes=c(".main",".yby"))
wex(massive)
view(massive)
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T)%>%
write.csv(.,file="Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-bigcombo.csv",fileEncoding = "Latin-1")
merge(massive,googledmerge,by.x="linkbase.yby",by.y="name",all.x=T,all.y=T)%>%
write.csv(.,file="Q:/Shared drives/FER - FPC Team/Website/Htmltables/Events-past-bigcombo.csv",fileEncoding = "Latin-1")
source("Q:/My Drive/Library/datlibmgr.R")
#Fresh R
#INGREDIENTS (FUN and LIBRARIES YOU'LL NEED)
library(ggrepel)
library(ggpmisc)
library(PerformanceAnalytics)
library(chron)
library(broom)
library(data.table) #YOU'LL NEED THE BUILT IN DATA.TABLE PACKAGE FOR FREAD
library(ggplot2)
library(lme4)
library(magrittr)
library(metafor)
library(nlme)
library(readr) #read_csv is from here
library(reshape) #YOULL NEED THIS FOR CAST
library(splitstackshape)
library(weights)
library(readxl)
library(devtools)
library(leaflet)
library(xts)
library(rnoaa)
library(maptools)
library(rgdal)
library(dismo)
library(rgl)
library(leaps)
library(plotly)
library(rsm)
library(tidyr)
library(lubridate)
library(robfilter)
library(XLConnect)
library(EMSaov)
library(car)
library(boot)
library(ggsignif)
library(lsmeans)
library(multcompView)
library(tibble)
library(purrr)
library(car)
library(proto)
library(gridGraphics)
library(phia)
library(ggstance)
library(lmerTest)
library(multcomp)
library(egg)
library(pracma)
library(plyr);library(dplyr) #YOULL NEED THIS FOR JOIN
library(Hmisc)
library(datapasta)
library(stringi)
library(xfun)
library(rlang)
library(digest)
library(mime)
library(htmltools)
library(rmarkdown)
library(ggpattern)
library(Rcpp)
library(sf) #errors as of 9/27 with "install.packages(sf)
#remotes::install_github("coolbutuseless/ggpattern") #ggpattern had some problems, at one point this fixed it
library(NCmisc)
library(RODBC)
library(stringr)
library(agricolaeplotr)
library(qpdf)
library(rvest) #web scraper
library(Rcrawler) #web scraper
library(xml2) #needed by rvest i think
library(RCurl)  #more web scraping stuff
library(httr) #needed for logins to websites and website sessions at least
library(gsheet) #read in google sheets
library(rlang)
library(googlesheets4) #needed for reading googlesheets (maybe better than gsheet)
library(googledrive) #needed for getting file, folder etc info from google drive
library(gmailr) #read and write gmails. needs some python to google api link I dont have time for as of 5/2/2023 so it doesn't do anything yet
library(urltools) #for getting domain from url among other things
library(googleVis) #get tables in html format
library(docxtractr)
library(tesseract) #for ocr
library(viridis)           #colors for ggplot
#install.packages("https://cran.r-project.org/src/contrib/Archive/rlang/rlang_1.1.0.tar.gz", repos = NULL, type="source")
library(dbscan) #for FPCALSpackage
#install.packages("https://cran.r-project.org/src/contrib/Archive/rlang/rlang_1.1.0.tar.gz", repos = NULL, type="source")
library(dbscan) #for FPCALSpackage
#Fresh R
#INGREDIENTS (FUN and LIBRARIES YOU'LL NEED)
library(ggrepel)
library(ggpmisc)
library(PerformanceAnalytics)
library(chron)
library(broom)
library(data.table) #YOU'LL NEED THE BUILT IN DATA.TABLE PACKAGE FOR FREAD
library(ggplot2)
library(lme4)
library(magrittr)
library(metafor)
library(nlme)
library(readr) #read_csv is from here
library(reshape) #YOULL NEED THIS FOR CAST
library(splitstackshape)
library(weights)
library(readxl)
library(devtools)
library(leaflet)
library(xts)
library(rnoaa)
library(maptools)
library(rgdal)
library(dismo)
library(rgl)
library(leaps)
library(plotly)
library(rsm)
library(tidyr)
library(lubridate)
library(robfilter)
library(XLConnect)
library(EMSaov)
library(car)
library(boot)
library(ggsignif)
library(lsmeans)
library(multcompView)
library(tibble)
library(purrr)
library(car)
library(proto)
library(gridGraphics)
library(phia)
library(ggstance)
library(lmerTest)
library(multcomp)
library(egg)
library(pracma)
library(plyr);library(dplyr) #YOULL NEED THIS FOR JOIN
library(Hmisc)
library(datapasta)
library(stringi)
library(xfun)
library(rlang)
library(digest)
library(mime)
library(htmltools)
library(rmarkdown)
library(ggpattern)
library(Rcpp)
library(sf) #errors as of 9/27 with "install.packages(sf)
#remotes::install_github("coolbutuseless/ggpattern") #ggpattern had some problems, at one point this fixed it
library(NCmisc)
library(RODBC)
library(stringr)
library(agricolaeplotr)
library(qpdf)
library(rvest) #web scraper
library(Rcrawler) #web scraper
library(xml2) #needed by rvest i think
library(RCurl)  #more web scraping stuff
library(httr) #needed for logins to websites and website sessions at least
library(gsheet) #read in google sheets
library(rlang)
library(googlesheets4) #needed for reading googlesheets (maybe better than gsheet)
library(googledrive) #needed for getting file, folder etc info from google drive
library(gmailr) #read and write gmails. needs some python to google api link I dont have time for as of 5/2/2023 so it doesn't do anything yet
library(urltools) #for getting domain from url among other things
library(googleVis) #get tables in html format
library(docxtractr)
library(tesseract) #for ocr
library(viridis)           #colors for ggplot
#install.packages("https://cran.r-project.org/src/contrib/Archive/rlang/rlang_1.1.0.tar.gz", repos = NULL, type="source")
library(dbscan) #for FPCALSpackage
library(deldir)#for FPCALSpackage
library(geometry)#for FPCALSpackage
#Fresh R
#INGREDIENTS (FUN and LIBRARIES YOU'LL NEED)
library(ggrepel)
library(ggpmisc)
library(PerformanceAnalytics)
library(chron)
library(broom)
library(data.table) #YOU'LL NEED THE BUILT IN DATA.TABLE PACKAGE FOR FREAD
library(ggplot2)
library(lme4)
library(magrittr)
library(metafor)
library(nlme)
library(readr) #read_csv is from here
library(reshape) #YOULL NEED THIS FOR CAST
library(splitstackshape)
library(weights)
library(readxl)
library(devtools)
library(leaflet)
library(xts)
library(rnoaa)
library(maptools)
library(rgdal)
library(dismo)
library(rgl)
library(leaps)
library(plotly)
library(rsm)
library(tidyr)
library(lubridate)
library(robfilter)
library(XLConnect)
library(EMSaov)
library(car)
library(boot)
library(ggsignif)
library(lsmeans)
library(multcompView)
library(tibble)
library(purrr)
library(car)
library(proto)
library(gridGraphics)
library(phia)
library(ggstance)
library(lmerTest)
library(multcomp)
library(egg)
library(pracma)
library(plyr);library(dplyr) #YOULL NEED THIS FOR JOIN
library(Hmisc)
library(datapasta)
library(stringi)
library(xfun)
library(rlang)
library(digest)
library(mime)
library(htmltools)
library(rmarkdown)
library(ggpattern)
library(Rcpp)
library(sf) #errors as of 9/27 with "install.packages(sf)
#remotes::install_github("coolbutuseless/ggpattern") #ggpattern had some problems, at one point this fixed it
library(NCmisc)
library(RODBC)
library(stringr)
library(agricolaeplotr)
library(qpdf)
library(rvest) #web scraper
library(Rcrawler) #web scraper
library(xml2) #needed by rvest i think
library(RCurl)  #more web scraping stuff
library(httr) #needed for logins to websites and website sessions at least
library(gsheet) #read in google sheets
library(rlang)
library(googlesheets4) #needed for reading googlesheets (maybe better than gsheet)
library(googledrive) #needed for getting file, folder etc info from google drive
library(gmailr) #read and write gmails. needs some python to google api link I dont have time for as of 5/2/2023 so it doesn't do anything yet
library(urltools) #for getting domain from url among other things
library(googleVis) #get tables in html format
library(docxtractr)
library(tesseract) #for ocr
library(viridis)           #colors for ggplot
#install.packages("https://cran.r-project.org/src/contrib/Archive/rlang/rlang_1.1.0.tar.gz", repos = NULL, type="source")
library(dbscan) #for FPCALSpackage
library(deldir)#for FPCALSpackage
library(geometry)#for FPCALSpackage
library(shiny)#for FPCALSpackage
library(shinyFiles)#for FPCALSpackage
library(shinyjs)#for FPCALSpackage
library(terra)#for FPCALSpackage
library(RCSF)#for FPCALSpackage
library(randomForest)#for FPCALSpackage
#library(FPCALSpackage)#for FPCALSpackage not avail for this version of r on home computer... fix this eventually
library(RSelenium) #driving webpages
library(qdap) #gsub but works on vectors of patterns
library(foreign) #for read.dbf
#Delete eventually if XLconnect doesnt give problems... as of 6/21 it was not installing or loading into the library for some reason so i needed to do this:
#require(devtools)
#install_version("XLConnect", version = "1.0.2", repos = "http://cran.us.r-project.org")
#Mend delete
select <- dplyr::select #otherwise it calls MASS's select by default
wex<- function(x,row.names=FALSE,col.names=TRUE,...) {
write.table(x,file="clipboard-32768",sep="\t",row.names=row.names,col.names=col.names,...)  }
source2 <- function(file, start, end, ...) {
file.lines <- scan(file, what=character(), skip=start-1, nlines=end-start+1, sep='\n')
file.lines.collapsed <- paste(file.lines, collapse='\n')
source(textConnection(file.lines.collapsed), ...)
}
#Get this working sometime. doesnt seem to work at least on longer paths???? not sure about shorter ones so try usuing it on shorter ones first
#src<-function(file_end){
#  source(paste0(getwd(),readClipboard()))
#}
if("you wnat to do flashcards"==T){
ANSWER<-"yes"
#loops thru and gives one column and the same row next too it one by one
fun <- function(dataf) {
ANSWER <- readline(cat("Are you a satisfied R user?\n\n\n "))
if (substr(ANSWER, 1, 1) == "n")
as.character(print((dataf[i-1,"cyl"])))
else
as.character(print((dataf[i,1])))
as.character(print(rownames(dataf[i,])))
}
#works dont fuck
for(i in c(1:4)){
fun(dataf = mtcars)
}
}
# Colorblind pallette to use with scale_fill_manual(values=cbPalette) for shape fills and scale_colour_manual(values=cbPalette) for  line and point colors
cbPalette <- c("#000000", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
#combine pdfs-----
qpdf::pdf_combine(input = c("Q:/My Drive/Studies/FPC/SharedFolderSean/Bloszies (1)/NCSU/Official/Pcard/Receipts/20230818_harvardapparatus_dialysisprobes.pdf",
"Q:/My Drive/Studies/FPC/SharedFolderSean/Bloszies (1)/NCSU/Official/Pcard/Receipts/20230912_harvardapparatus_dialysisprobes.pdf"),
output = "Q:/My Drive/Studies/FPC/SharedFolderSean/Bloszies (1)/NCSU/Official/Pcard/Receipts/20230912_harvardapparatus_dialysisprobes2.pdf")
source("Q:/My Drive/Library/datlibmgr.R")
setwd("Q:/My Drive/Studies/FPC/Scripts")
